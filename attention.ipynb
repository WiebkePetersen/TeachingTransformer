{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a82070a",
   "metadata": {},
   "source": [
    "# Self attention\n",
    "\n",
    "## Self attention without learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e38e7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of basic functions\n",
    "\n",
    "# vector addition\n",
    "def vectorAdd(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"different vector lengths\")\n",
    "    return [v1[i] + v2[i] for i in range(len(v1))]\n",
    "\n",
    "\n",
    "# vector addition for a list of vectors\n",
    "def vectorAddList(vectorlist):\n",
    "    v= vectorlist[0]\n",
    "    for vi in vectorlist[1:]:\n",
    "        v = vectorAdd(v, vi)\n",
    "    return v\n",
    "\n",
    "# scalar multiplication (vector)\n",
    "def scalarMult(scalar, v):\n",
    "    return [scalar * v[i] for i in range(len(v))]\n",
    "\n",
    "# dot product\n",
    "def dot(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"different vector lengths\")\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "\n",
    "\n",
    "# transpose\n",
    "def t(M):\n",
    "    return [[M[i][j] for i in range(len(M))] for j in range(len(M[0]))]\n",
    "\n",
    "# matrix addition\n",
    "def addMatrix(M1,M2):\n",
    "    return [[M1[i][j] + M2[i][j] for j in range(len(M1[0]))] for i in range(len(M1))]\n",
    "\n",
    "\n",
    "def multMatrix(M1,M2):\n",
    "    # [[dot(ite Zeile von M1, jte Spalte von M2) for j in range(len(tM2))] for i in range(len(M1))]\n",
    "    tM2 = t(M2)\n",
    "    return [[dot(M1[i], tM2[j]) for j in range(len(tM2))] for i in range(len(M1))]\n",
    "\n",
    "# listvector to matrix \n",
    "def v2m(v):\n",
    "    return [v]\n",
    "\n",
    "# 1-row matrix to vector: \n",
    "def m2v(v):\n",
    "    return v[0]\n",
    "\n",
    "\n",
    "def prettyprint(M):\n",
    "    for i in range(len(M)):\n",
    "        print(str(M[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2c1aaf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = [2, 2, 4] [2, 2, 4]\n",
      "2*a = [2, 4, 6]\n",
      "a . b = 4\n"
     ]
    }
   ],
   "source": [
    "a= [1,2,3] \n",
    "b= [1,0,1]\n",
    "print(\"a + b =\", vectorAdd(a, b), vectorAddList([a,b]))\n",
    "print(\"2*a =\", scalarMult(2, a))\n",
    "print(\"a . b =\", dot(a, b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eaecb8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5]\n",
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "prettyprint(t([[1,2],[3,4],[5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d3f72ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2m([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7c4d2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4]\n",
      "[5, 6]\n",
      "\n",
      "[-1, -3, 5]\n",
      "[-2, -4, 6]\n",
      "\n",
      "[-5, -11, 17]\n",
      "[-11, -25, 39]\n",
      "[-17, -39, 61]\n",
      "\n",
      "[15, 16]\n",
      "[16, 16]\n"
     ]
    }
   ],
   "source": [
    "M1 = [[1,2],[3,4],[5,6]]\n",
    "M2 = [[-1,-2],[-3,-4],[5,6]]\n",
    "prettyprint(M1)\n",
    "print()\n",
    "prettyprint(t(M2))\n",
    "print()\n",
    "prettyprint(multMatrix(M1,t(M2)))\n",
    "print()\n",
    "prettyprint(multMatrix(t(M1),M2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f3cf3",
   "metadata": {},
   "source": [
    "Softmax Funktion $\\sigma$:\n",
    "\n",
    "$\\sigma: \\mathbf{R}^K \\rightarrow (0,1)^K$ normalisierte Exponentialfunktion mit \n",
    "\n",
    "$ \\sigma(\\vec{x})_i = \\frac{e^{x_{i}}}{\\sum_{j=1}^K e^{x_{j}}}  \\ for\\ i=1,2,\\dots,K  $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6f9a7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 2.718281828459\n",
    "\n",
    "def softmax(x):\n",
    "    return [e**x[i] / sum(e**x[j] for j in range(len(x))) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6fd8c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] softmax = [0.09003057317038284, 0.24472847105480003, 0.6652409557748171]\n",
      "[1, 0, 1] softmax = [0.4223187982515171, 0.1553624034969658, 0.4223187982515171]\n",
      "[1, -10, -10] softmax = [0.576116884765825, 0.21194155761708747, 0.21194155761708747]\n",
      "[4] softmax = [1.0]\n"
     ]
    }
   ],
   "source": [
    "print(a,\"softmax =\", softmax(a))\n",
    "print(b,\"softmax =\", softmax(b))\n",
    "print([1,-10,-10],\"softmax =\", softmax([1,0,0]))\n",
    "print([4],\"softmax =\", softmax([4]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44873534",
   "metadata": {},
   "source": [
    "$\\alpha$ ist die Relevanzmatrix, die sich aus dem Vergleich der Wortvektoren untereinander ergibt. Sei $L$ die Eingangstextlänge, dann ist\n",
    "\n",
    "$\\alpha_{ij} = softmax(score(x_i,x_j))\\ \\forall i,j \\leq K$ die Relevanzmatrix.\n",
    "\n",
    "Im Falle von *masked attention* vergleicht man den Wortvektor nur mit den vorangegangenen. Damit ergeben sich für ein Wort $x_i$ die Relevanzwerte:\n",
    "\n",
    "$\\alpha_{ij} = softmax(score(x_i,x_j))\\ \\forall j \\leq i$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a31345a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x,y):\n",
    "    return dot(x,y)\n",
    "\n",
    "def alpha_masked(x): # x ist eine Liste von Wortvektoren\n",
    "    alpha = []\n",
    "    for i in range(len(x)):\n",
    "        row = []\n",
    "        for j in range(i+1):\n",
    "            row.append(score(x[i], x[j]))\n",
    "        alpha.append(softmax(row))\n",
    "    return alpha\n",
    "\n",
    "def alpha_masked_matrix(x): # x ist eine Liste von Wortvektoren\n",
    "    alpha = []\n",
    "    for i in range(len(x)):\n",
    "        row = []\n",
    "        for j in range(len(x)):\n",
    "            if j <= i:\n",
    "                row.append(score(x[i], x[j]))\n",
    "            else:\n",
    "                row.append(-float('inf'))  # use a large value to represent masked positions\n",
    "        alpha.append(softmax(row))\n",
    "    return alpha\n",
    "    \n",
    "def alpha(x): # x ist eine Liste von Wortvektoren\n",
    "    alpha = []\n",
    "    for i in range(len(x)):\n",
    "        row = []\n",
    "        for j in range(len(x)):\n",
    "            row.append(score(x[i], x[j]))\n",
    "        alpha.append(softmax(row))\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1fd8a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.9999484585145457, 4.539758978267296e-05, 6.143895671497805e-06],\n",
       "  [0.9908674725821718, 0.006676412513377005, 0.002456114904451198],\n",
       "  [0.9646631559719018, 0.017668422014049192, 0.017668422014049192]],\n",
       " [[1.0],\n",
       "  [0.9933071490757145, 0.006692850924285412],\n",
       "  [0.9646631559719018, 0.017668422014049192, 0.017668422014049192]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist = [[2,4], [1,2], [0,2]]\n",
    "alpha(vectorlist), alpha_masked(vectorlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9286f",
   "metadata": {},
   "source": [
    "Der kontextualisierte Output-Vektor  $y_i$ zu einem Inputvektor $x_i$ gegeben eine Liste von Wortvektoren $[x_j\\ j\\leq i]$ ist:\n",
    "\n",
    "$$ y_i = \\sum_{j\\leq i} \\alpha_{i,j} x_j  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "70d1ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contextualized(x): # x ist eine Liste von Wortvektoren\n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        a = alpha_masked(x)\n",
    "        yi = vectorAddList([scalarMult(a[i][j] ,x[j]) for j in range(i+1)])\n",
    "        y.append(yi)\n",
    "    return y\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "25a10d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0],\n",
       " [1.0, 1.0],\n",
       " [1.0, 1.5752103826044344],\n",
       " [1.8649548767993709, 1.9798697812543224]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualized([[1,2], [1,0], [1,1], [2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cfde19d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2, 4], [1, 2], [2, 0.1]],\n",
       " [[2.0, 4.0],\n",
       "  [1.9933071490757144, 3.9866142981514288],\n",
       "  [1.938024701975659, 2.399131881320575]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist = [[2, 4], [1, 2], [2, 0.1]]\n",
    "vectorlist, contextualized(vectorlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e86602",
   "metadata": {},
   "source": [
    "Liste von Wortvektoren: $[[2, 4], [1, 2], [2, 0.1]]$\n",
    "Detaillierte Berechnung von $$ y_2 = \\sum_{j\\leq 2} \\alpha_{2,j} x_j = \\alpha_{2,0} x_0 + \\alpha_{2,1} x_1 + \\alpha_{2,2} x_2 $$ \n",
    "$$ [\\alpha_{2,0},\\alpha_{2,1},\\alpha_{2,2}] = softmax([score(x_2,x_0), score(x_2,x_1), score(x_2,x_2)] )  = \\\\\n",
    "softmax([4.4,2.2,4.01]) \\approx [0.56,0.06,0.38] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf535a",
   "metadata": {},
   "source": [
    "**Vorsicht**: Der Vektor [2,0.1] hat ein höheres dot-Produkt mit dem Vektor [2,4] als mit sich selbst. Dies widerspricht der Idee, dass das dot-Produkt hier Ähnlichkeit modellieren soll. Ein Ausweg ist die explizite L2-Normalisierung der Wort-Embeddings:\n",
    "Bevor das Dot-Produkt zur Berechnung von Relevanz-Scores verwendet wird, werden die Wortvektoren (Embeddings) explizit auf die Länge 1 normiert.\n",
    "\n",
    "Statt einem Vektor $u$ wird der Vektor $\\frac{u}{\\|u\\|}$ genutzt. Damit wird das dot-Produkt zur Cosinus-Ähnlichkeit: \n",
    "$$\\text{cosine\\_similarity}(u, v) = \\frac{u \\cdot v}{\\|u\\| \\cdot \\|v\\|}$$\n",
    "\n",
    "Hier werden wir dieses Problem erst einmal vernachlässigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c22a6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus: embedding of 'chair'\n",
      "uncontextualized embedding of chair is [3, 4, 3]\n",
      "uncontextualized embedding of seesion is [7, 2, 1]\n",
      "uncontextualized embedding of person is [1, 2, 7]\n",
      "\n",
      "contextualized embedding of chair in ['each', 'session', 'has', 'a', 'chair'] is\n",
      "[3.488241706560337, 3.3861879899594367, 3.1255703034802282]\n",
      "\n",
      "contextualized embedding of chair in ['each', 'person', 'has', 'a', 'chair'] is\n",
      "[3.1255703034802282, 3.3861879899594367, 3.4882417065603373]\n"
     ]
    }
   ],
   "source": [
    "w1 = \"each\"\n",
    "wa2 = \"session\"\n",
    "wb2 = \"person\"\n",
    "w3 = \"has\"\n",
    "w4 = \"a\"\n",
    "w5 = \"chair\"\n",
    "\n",
    "\n",
    "\n",
    "v1 = [4,3,3]\n",
    "va2 = [7,2,1]\n",
    "vb2 = [1,2,7]\n",
    "v3 = [3.5,3,3.5]\n",
    "v4 = [3,3,4]\n",
    "v5 = [3,4,3]\n",
    "\n",
    "s1 = [w1, wa2, w3, w4, w5]\n",
    "s2 = [w1, wb2, w3, w4, w5]\n",
    "\n",
    "\n",
    "embeddings = {w1:v1, wa2:va2, wb2:vb2, w3:v3, w4:v4, w5:v5}\n",
    "\n",
    "print(\"Focus: embedding of '{}'\".format(w5))\n",
    "\n",
    "print(\"uncontextualized embedding of\", \"chair\", \"is\", embeddings[\"chair\"]) \n",
    "print(\"uncontextualized embedding of\", \"seesion\", \"is\", embeddings[\"session\"] ) \n",
    "print(\"uncontextualized embedding of\", \"person\", \"is\", embeddings[\"person\"]) \n",
    "print(\"\\ncontextualized embedding of\", \"chair\", \"in\", s1, \"is\")\n",
    "print(contextualized([embeddings[w] for w in s1])[-1])\n",
    "print(\"\\ncontextualized embedding of\", \"chair\", \"in\", s2, \"is\")\n",
    "print(contextualized([embeddings[w] for w in s2])[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb9cbc",
   "metadata": {},
   "source": [
    "## Self attention with learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1722ba",
   "metadata": {},
   "source": [
    "<img src=\"JM_F_9_10.png\" width=\"500\"> \n",
    "\n",
    "Aus Jurafsky & Martin (3rd edition, draft, January 12, 2025 release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b9398684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7, 13, 6]\n",
      "\n",
      "[-7, -13, 8]\n",
      "\n",
      "[4, 3, -2, 7]\n"
     ]
    }
   ],
   "source": [
    "# Berechnung von projezierten Rollen-Vektoren\n",
    "WQ = [[1,2,1],[-1,1,0],[-2,1,1]]\n",
    "WK =  [[-1,-2,-1],[-1,-1,2],[0,-1,1]]\n",
    "WV = [[-1,1,-2,2],[1,0,1,1],[1,0,0,-1]]\n",
    "\n",
    "prettyprint(multMatrix(v2m(v5), WQ)) \n",
    "print()\n",
    "prettyprint(multMatrix(v2m(v5), WK))\n",
    "print()\n",
    "prettyprint(multMatrix(v2m(v5), WV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358b8f0",
   "metadata": {},
   "source": [
    "<img src=\"JM_9_4.png\" width=\"500\"> \n",
    "\n",
    "Aus Jurafsky & Martin (3rd edition, draft, January 12, 2025 release)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2aa234",
   "metadata": {},
   "source": [
    "<img src=\"JM_9_8\n",
    ".png\" width=\"500\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7b2f6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satz: ['each', 'session', 'has', 'a', 'chair']\n",
      "Schritt 1: Embeddings [[4, 3, 3], [7, 2, 1], [3.5, 3, 3.5], [3, 3, 4], [3, 4, 3]]\n",
      "Schritt 2: projezierte Rollenvektoren [{'k': [[-7, -14, 5]], 'q': [[-5, 14, 7]], 'v': [[2, 4, -5, 8]]}, {'k': [[-9, -17, -2]], 'q': [[3, 17, 8]], 'v': [[-4, 7, -12, 15]]}, {'k': [[-6.5, -13.5, 6.0]], 'q': [[-6.5, 13.5, 7.0]], 'v': [[3.0, 3.5, -4.0, 6.5]]}, {'k': [[-6, -13, 7]], 'q': [[-8, 13, 7]], 'v': [[4, 3, -3, 5]]}, {'k': [[-7, -13, 8]], 'q': [[-7, 13, 6]], 'v': [[4, 3, -2, 7]]}]\n"
     ]
    }
   ],
   "source": [
    "# Schrittweise Berechnung des 3. Outputs\n",
    "print(\"Satz:\",s1)\n",
    "s_embedded = [embeddings[w] for w in s1]\n",
    "print(\"Schritt 1: Embeddings\", s_embedded)\n",
    "rollen = [ {\"k\": multMatrix(v2m(v), WK), \"q\": multMatrix(v2m(v), WQ), \"v\": multMatrix(v2m(v), WV)} for v in s_embedded]\n",
    "print(\"Schritt 2: projezierte Rollenvektoren\", rollen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbd6b5",
   "metadata": {},
   "source": [
    "$$ score(x_i,x_j) = \\frac{q_i\\cdot q_j}{\\sqrt{d_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be431970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neue Sorefunktion mit erlernten Parametern\n",
    "def scoreL(x1,x2):\n",
    "    q1 = multMatrix(v2m(x1), WQ)\n",
    "    k2 = multMatrix(v2m(x2), WK)\n",
    "    return dot(m2v(q1),m2v(k2)) / len(x1)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a2f6282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.0, 3.5, -4.0, 6.5]]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollen[2][\"v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0dd9ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schritt 3: Inputvektor für Softmax-layer [-91, -163, -81.5]\n",
      "Schritt 4: Softmax scores [7.484622751062311e-05, 4.026866373829326e-36, 0.9999251537724895]\n",
      "Schritt 5: Weight each vector [[0.00014969245502124623, 0.00029938491004249246, -0.0003742311375531156, 0.0005987698200849849], [-1.6107465495317303e-35, 2.818806461680528e-35, -4.832239648595191e-35, 6.040299560743989e-35], [2.9997754613174683, 3.4997380382037133, -3.999700615089958, 6.499513499521181]]\n",
      "Schritt 6: Weighted sum [2.9999251537724896, 3.500037423113756, -4.000074846227511, 6.500112269341266]\n"
     ]
    }
   ],
   "source": [
    "# Input in softmax für 3. Wort\n",
    "\n",
    "input = [scoreL(s_embedded[3],s_embedded[j]) for j in range(3)]\n",
    "print(\"Schritt 3: Inputvektor für Softmax-layer\", input )\n",
    "print(\"Schritt 4: Softmax scores\", softmax(input) )\n",
    "weighted = [scalarMult(softmax(input)[i], m2v(rollen[i][\"v\"])) for i in range(3)]\n",
    "print(\"Schritt 5: Weight each vector\", weighted)\n",
    "print(\"Schritt 6: Weighted sum\", vectorAddList(weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cf69b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schritt 7: Reshaping to embedding dimension [[-10.500411654251309, -1.5001871155687763, 15.499962576886247]]\n",
      "\n",
      "Contextualized embedding for 3rd word [[-10.500411654251309, -1.5001871155687763, 15.499962576886247]]\n"
     ]
    }
   ],
   "source": [
    "# reshaping nedessary to get back to embedding dimension\n",
    "WO = [[1,1,2],[3,1,2],[6,2,1],[0,0,1]]\n",
    "print(\"Schritt 7: Reshaping to embedding dimension\", multMatrix(v2m(vectorAddList(weighted)),WO))\n",
    "print()\n",
    "print(\"Contextualized embedding for 3rd word\", multMatrix(v2m(vectorAddList(weighted)),WO))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f2feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
